Here's a manifest of the metadata construction:
Core Episode Identifiers & URLs:
Fields: podcast, episode (title), guid, published (date), episode_url, audio_url.
Source: Primarily from the RSS feed.
Construction:
backfill_test.py (process function): Directly extracted from the entry object (parsed feed item) and podcast (feed title), feed_url arguments.
podcast_insights/meta_utils.py (enrich_meta function): Also populates these from the entry and feed_title if not already present, ensuring consistency.
Processing Provenance & Timestamps:
Fields: asr_model, processed_date, processed_by.
Construction:
backfill_test.py (process function):
asr_model: Set using the MODEL_VERSION global variable (e.g., "whisper-base-2025-05-23").
processed_date: Set using dt.datetime.utcnow().isoformat().
processed_by: Hardcoded to "backfill_test.py".
Audio Technical Details:
Fields: sample_rate_hz, bitrate_kbps, duration_sec, speech_music_ratio, audio_hash, download_path.
Construction:
backfill_test.py (process function):
get_audio_tech() (from podcast_insights/audio_utils.py): Provides sample rate, bitrate, duration.
estimate_speech_music_ratio() (from podcast_insights/audio_utils.py): Calculates speech vs. music.
calculate_audio_hash() (from podcast_insights/audio_utils.py): Generates a hash of the audio file.
download_path: Path to the downloaded MP3.
These are collected into the tech dictionary and then spread into the main meta object.
Transcription & ASR Quality Metrics:
Fields: supports_timestamp, transcript_length, avg_confidence, wer_estimate, segment_count, chunk_count, transcript_path.
Construction:
podcast_insights/meta_utils.py (process_transcript function, called by backfill_test.py):
supports_timestamp: Checks if segments have start times.
transcript_length: Length of the transcribed text.
calculate_confidence(): Calculates avg_confidence and wer_estimate from segment data.
backfill_test.py (process function):
segment_count: Number of segments in the transcript.
chunk_count: Number of audio chunks processed.
transcript_path: Absolute path to the final transcript JSON file.
Content-Derived Metadata (NLP, Enrichment):
Fields: categories, hosts, guests, keywords, itunes_episodeType, is_trailer, rights (copyright, explicit).
Construction:
podcast_insights/meta_utils.py (enrich_meta function, called by backfill_test.py):
categories: Extracted from feed entry.tags.
extract_people() & tidy_people(): Determine hosts and guests from RSS <podcast:person> tags and NER on the transcript.
extract_keywords(): Generates TF-IDF based keywords from transcript and show notes.
get_episode_type(): Determines itunes_episodeType and is_trailer.
get_explicit_flag(): Determines rights.explicit.
rights.copyright: From feed.
Cached NLP/Data File Paths:
segments_path:
Construction: backfill_test.py (process function).
Content: A JSON file containing a list of [start_time, end_time] tuples for each segment. Saved in data/segments/{audio_hash}.json.
entities_path:
Construction: podcast_insights/transcribe.py (called as a subprocess by backfill_test.py). If caching is enabled, transcribe.py calls _generate_spacy_entities_file (from podcast_insights/meta_utils.py).
Content: A JSON file containing a list of extracted SpaCy entities, e.g., [{"text": "OpenAI", "type": "ORG", ...}]. Saved in data/entities/{guid}.json. The path is then added to the transcript JSON's meta block by transcribe.py.
backfill_test.py then reads this path from the transcript's meta if present.
embedding_path:
Construction: Similar to entities_path, generated by transcribe.py calling _generate_sentence_embedding_file (from podcast_insights/meta_utils.py).
Content: A .npy file containing the sentence embedding vector for the transcript. Saved in data/embeddings/{guid}.npy. Path added to transcript's meta.
backfill_test.py reads this path.
Primary Files and their Roles in Metadata Construction:
backfill_test.py:
Orchestrates the entire pipeline for new episodes.
Initializes meta object with feed data, audio technical info, and processing provenance.
Calls run_transcribe (which executes podcast_insights/transcribe.py as a subprocess).
Retrieves the transcript data (which might include entities_path and embedding_path in its meta if transcribe.py cached them).
Calls enrich_meta and process_transcript from podcast_insights/meta_utils.py to further populate and refine the meta object.
Crucially, it assembles the enriched_meta_obj which becomes transcript_data["meta"] and is saved to the final JSON file.
Generates and saves segments_path.
podcast_insights/transcribe.py:
Performs the core audio-to-text transcription.
If caching is enabled (--enable_caching flag, which backfill_test.py uses):
Calls _generate_spacy_entities_file to create entities.json and stores entities_path in its output JSON's meta.
Calls _generate_sentence_embedding_file to create embedding.npy and stores embedding_path in its output JSON's meta.
podcast_insights/meta_utils.py:
enrich_meta(): Central function for adding semantic metadata (keywords, people, categories, etc.) by processing transcript text and feed data.
process_transcript(): Adds transcript-specific metrics (length, confidence, etc.).
_generate_spacy_entities_file(): Creates and saves the SpaCy entities JSON file.
_generate_sentence_embedding_file(): Creates and saves the sentence embedding NumPy file.
Other helper functions for specific extractions (extract_keywords, extract_people, etc.).
rebuild_meta.py:
Used for reprocessing existing transcript files to update/add metadata without re-transcribing.
Calls enrich_meta directly. It can also generate entities/embeddings if the --compute_embeddings flag is set, in which case it loads the necessary NLP models itself.
This breakdown should give a clearer picture of how and where each piece of metadata is incorporated into the final JSON output. The backfill_test.py script is the main point of assembly for newly processed episodes.
